{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë²ˆì—­ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve import RemoteRunnable\n",
    "\n",
    "# ngrok remote ì£¼ì†Œ ì„¤ì •\n",
    "# chain = RemoteRunnable(\"https://poodle-deep-marmot.ngrok-free.app/translate/\")\n",
    "chain = RemoteRunnable(\"NGROK ì—ì„œ ì„¤ì •í•œ ë³¸ì¸ì˜ ë„ë©”ì¸ ì£¼ì†Œ/translate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” ë”¥ëŸ¬ë‹ì„ ì •ë§ ì¢‹ì•„í•´ìš”!"
     ]
    }
   ],
   "source": [
    "for token in chain.stream({\"input\": \"I love deep learning\"}):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM ì„ Runnableë¡œ ì‹¤í–‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langserve import RemoteRunnable\n",
    "\n",
    "# llm = RemoteRunnable(\"https://poodle-deep-marmot.ngrok-free.app/llm/\")\n",
    "llm = RemoteRunnable(\"NGROK ì—ì„œ ì„¤ì •í•œ ë³¸ì¸ì˜ ë„ë©”ì¸ ì£¼ì†Œ/llm/\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"ë‹¤ìŒì˜ ë‚´ìš©ì„ SNS ê²Œì‹œê¸€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ ì£¼ì„¸ìš”:\\n{input}\"\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ğŸ‰ğŸ’» ì¸ê³µì§€ëŠ¥ ì¡°ìˆ˜ë¡œì„œ ì €ëŠ” ë”¥ëŸ¬ë‹ì— ëŒ€í•œ ì‚¬ë‘ì„ ê°ì¶œ ìˆ˜ ì—†ì–´ìš”! ğŸ¤–ğŸŒŸ ì´ ê°•ë ¥í•œ ê¸°ìˆ ì€ ë°ì´í„° ê³¼í•™ ë° AI ë¶„ì•¼ë¥¼ í˜ì‹ ì ìœ¼ë¡œ ë³€í™”ì‹œì¼°ìŠµë‹ˆë‹¤. #AI #ML ğŸš€ #DeepLearning\\n\\në”¥ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ ìš°ë¦¬ê°€ ì˜ˆì¸¡, ë¶„ì„, ì˜ì‚¬ê²°ì • ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ë° ë„ì›€ì„ ì£¼ë©°, ë³µì¡í•œ ë°ì´í„°ë¥¼ ì´í•´í•˜ëŠ” ë° ìˆì–´ ì¤‘ìš”í•œ ì—­í• ì„ í•˜ê³  ìˆì–´ìš”!ğŸ§ ğŸ”¬ğŸ“Š #MachineLearning\\n\\nì €ì˜ AI ì¡°ìˆ˜ë¡œì„œì˜ ì„ë¬´ ì¤‘ í•˜ë‚˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì—°êµ¬í•˜ê³  í›ˆë ¨ì‹œì¼œ ì—¬ëŸ¬ë¶„ì´ ì œ ë‹µë³€ì„ ë” ìœ ìš©í•˜ê²Œ ë§Œë“¤ê³ , ì¼ìƒìƒí™œì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.ğŸ˜ŠğŸ¤–\\n\\nì•ìœ¼ë¡œ ìš°ë¦¬ê°€ ë”¥ëŸ¬ë‹ê³¼ í•¨ê»˜ ë¬´ì—‡ì„ ì´ë£°ì§€ ìƒìƒí•´ë³´ì„¸ìš” - ì˜ë£Œ ì§„ë‹¨ë¶€í„° ììœ¨ì£¼í–‰ì°¨ëŸ‰ì— ì´ë¥´ê¸°ê¹Œì§€, ê°€ëŠ¥ì„±ì€ ë¬´ê¶ë¬´ì§„í•©ë‹ˆë‹¤!ğŸš€âœ¨ #FutureOfAI #DeepLearningAdvancements\\n\\nAIì™€ ë¨¸ì‹ ëŸ¬ë‹ì˜ ì„¸ê³„ëŠ” í¥ë¯¸ë¡­ê³  ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìœ¼ë©°, ì €ëŠ” ì´ ì—¬ì •ì„ ì—¬ëŸ¬ë¶„ê³¼ í•¨ê»˜ í•  ìˆ˜ ìˆì–´ ê¸°ì©ë‹ˆë‹¤. ğŸ“ˆğŸ’¡ ë‹¤ìŒì— ì œê°€ ë”¥ëŸ¬ë‹ì— ëŒ€í•´ ë¬´ì—‡ì„ ë°°ìš¸ì§€ ê¸°ëŒ€í•´ ì£¼ì„¸ìš”! #StayCurious #LearnTogether\\n\\n#AICommunity #DeepLearningLovers #MachineLearningEnthusiasts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"ì €ëŠ” ë”¥ëŸ¬ë‹ì„ ë„ˆë¬´ë‚˜ë„ ì‚¬ë‘í•©ë‹ˆë‹¤.\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
